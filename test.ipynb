{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99e488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5113, 0.1161, 1.9593])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn((2,3))\n",
    "mask = torch.tensor([[1, 0, 0], [1, 1, 0]], dtype=torch.bool)\n",
    "a[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "573ab6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7494,  0.1406, -0.3523,  0.2796, -0.4618],\n",
      "         [ 0.2052,  0.3606, -0.9348, -0.5974,  0.4900],\n",
      "         [ 2.7700,  0.0216, -1.9388,  0.0586,  0.6073]],\n",
      "\n",
      "        [[ 2.1189,  1.2294, -0.2514, -0.4429, -0.2362],\n",
      "         [ 0.5698,  1.2466, -1.0717,  0.8464, -1.4920],\n",
      "         [-0.3821,  0.6153, -0.2265, -0.4393, -0.2794]]])\n",
      "(tensor([[[-0.6033,  0.0134, -0.2445, -0.0824, -0.9429],\n",
      "         [ 0.4384,  0.5902, -1.2939, -0.3002,  0.4658],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.6710,  0.1496, -0.1850,  0.0094, -0.5892],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
      "       grad_fn=<PermuteBackward0>), {'z': tensor([[[[-0.7506,  0.1408, -0.3529,  0.2800, -0.4625]],\n",
      "\n",
      "         [[ 0.1601,  0.2813, -0.7293, -0.4661,  0.3823]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000,  0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8431,  0.4892, -0.1000, -0.1762, -0.0940]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[-0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]]]), 'z_q': tensor([[[[-0.6033,  0.0134, -0.2445, -0.0824, -0.9429]],\n",
      "\n",
      "         [[ 0.4384,  0.5902, -1.2939, -0.3002,  0.4658]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.6710,  0.1496, -0.1850,  0.0094, -0.5892]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "         [[ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000]]]],\n",
      "       grad_fn=<MulBackward0>), 'd': tensor([[[0.6417],\n",
      "         [0.7253],\n",
      "         [0.8772]],\n",
      "\n",
      "        [[0.6572],\n",
      "         [0.6091],\n",
      "         [0.8866]]]), 'q': tensor([[[ 81],\n",
      "         [  0],\n",
      "         [122]],\n",
      "\n",
      "        [[122],\n",
      "         [ 97],\n",
      "         [ 20]]]), 'loss': tensor(0.0457, grad_fn=<MeanBackward0>), 'perplexity': None})\n"
     ]
    }
   ],
   "source": [
    "from vqtorch.nn import  VectorQuant\n",
    "import torch\n",
    "inplace_optimizer = lambda *args, **kwargs: torch.optim.SGD(*args, **kwargs, lr=50.0, momentum=0.9)\n",
    "vq = VectorQuant(\n",
    "            feature_size=5,     # feature dimension corresponding to the vectors\n",
    "            num_codes=128,      # number of codebook vectors\n",
    "            beta=1.0,           # (default: 0.9) commitment trade-off\n",
    "            kmeans_init=False,    # (default: False) whether to use kmeans++ init\n",
    "            norm='l2',           # (default: None) normalization for the input vectors\n",
    "            cb_norm='l2',        # (default: None) normalization for codebook vectors\n",
    "            affine_lr=10,      # (default: 0.0) lr scale for affine parameters\n",
    "            sync_nu=0.2,         # (default: 0.0) codebook synchronization contribution\n",
    "            replace_freq=20,     # (default: None) frequency to replace dead codes\n",
    "            dim=-1,             # (default: -1) dimension to be quantized\n",
    "            affine_groups=4,\n",
    "            inplace_optimizer = inplace_optimizer\n",
    "        )\n",
    "\n",
    "input = torch.randn((2,3,5))\n",
    "print(input)\n",
    "mask = torch.tensor([[1,1,0],[1,0,0]])\n",
    "output = vq(input, mask)\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RGG-VAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
